
Problem Statement:
Analyze the Retail Purchase data set and implement the KPIâ€™s as defined below:
1.Calculate sales breakdown by product category across all of the stores.
2.Calculate sales break down by store across all of the stores. Assume there is one store per city
3. Find the total sales values across all the stores and the total number of sales.

Data Download Link
https://www.dropbox.com/s/9f78fnvc2ditssl/Retail_Sample_Data_Set.txt?dl=0

//1. Calculate sales breakdown by product category across all of the stores.
package com.df.retail

import scala.math.random

import org.apache.spark.sql.SparkSession
import java.lang.Float


object ProductSales {
	def main(args: Array[String]) {

		if (args.length < 2) {
			System.err.println("Usage: ProductSales <Input-File> <Output-File>");
			System.exit(1);
		}

		val spark = SparkSession
				.builder
				.appName("ProductSales")
				.getOrCreate()

		val data = spark.read.textFile(args(0)).rdd

		val result = data.map { line => {
  		val tokens = line.split("\\t")
		  (tokens(3), Float.parseFloat(tokens(4)))
		}}
//		Prod-Cat  Sale-Val
//		Women's Clothing   153.57
//		Women's Clothing	 483.82
		.reduceByKey(_+_)

		result.saveAsTextFile(args(1))

		spark.stop
	}
}
//bin/spark-submit --class com.df.retail.ProductSales ../retailJob.jar ../Retail_Sample_Data_Set.txt ret-out-01



KPI 2



//2. Calculate sales breakdown by storeacross all of the stores. Assume there is one store per city
package com.df.retail

import scala.math.random

import org.apache.spark.sql.SparkSession
import java.lang.Float

object StoreSales {
	def main(args: Array[String]) {

		if (args.length < 2) {
			System.err.println("Usage: StoreSales <Input-File> <Output-File>");
			System.exit(1);
		}

		val spark = SparkSession
				.builder
				.appName("StoreSales")
				.getOrCreate()

		val data = spark.read.textFile(args(0)).rdd

		val result = data.map { line => {
  		val tokens = line.split("\\t")
		  (tokens(2), Float.parseFloat(tokens(4)))
		}}

		.reduceByKey(_+_)

		result.saveAsTextFile(args(1))

		spark.stop
	}
}
//bin/spark-submit --class com.df.retail.StoreSales ../retailJob.jar ../Retail_Sample_Data_Set.txt ret-out-02


KPI 3

//3. Find the total sales values across all the stores and the total number of sales.


package com.df.retail

import scala.math.random

import org.apache.spark.sql.SparkSession
import java.lang.Float


object TotalSales {
	def main(args: Array[String]) {

		if (args.length < 2) {
			System.err.println("Usage: TotalSales <Input-File> <Output-File>");
			System.exit(1);
		}

		val spark = SparkSession
				.builder
				.appName("TotalSales")
				.getOrCreate()

		val data = spark.read.textFile(args(0)).rdd

		val result = data.map { line => {
  		val tokens = line.split("\\t")
		  Float.parseFloat(tokens(4))
		}}
		val sum = result.sum()
		val count = result.count()

		spark.sparkContext.parallelize(Seq(sum, count), 1).saveAsTextFile(args(1))

		spark.stop
	}
}
//bin/spark-submit --class com.df.retail.TotalSales ../retailJob.jar ../Retail_Sample_Data_Set.txt ret-out-03
